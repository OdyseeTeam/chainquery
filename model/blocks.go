// Code generated by SQLBoiler (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package model

import (
	"bytes"
	"database/sql"
	"fmt"
	"reflect"
	"strings"
	"sync"
	"time"

	"github.com/pkg/errors"
	"github.com/volatiletech/sqlboiler/boil"
	"github.com/volatiletech/sqlboiler/queries"
	"github.com/volatiletech/sqlboiler/queries/qm"
	"github.com/volatiletech/sqlboiler/strmangle"
	"gopkg.in/volatiletech/null.v6"
)

// Block is an object representing the database table.
type Block struct {
	ID                    uint64      `boil:"id" json:"id" toml:"id" yaml:"id"`
	Bits                  string      `boil:"bits" json:"bits" toml:"bits" yaml:"bits"`
	Chainwork             string      `boil:"chainwork" json:"chainwork" toml:"chainwork" yaml:"chainwork"`
	Confirmations         uint        `boil:"confirmations" json:"confirmations" toml:"confirmations" yaml:"confirmations"`
	Difficulty            string      `boil:"difficulty" json:"difficulty" toml:"difficulty" yaml:"difficulty"`
	Hash                  string      `boil:"hash" json:"hash" toml:"hash" yaml:"hash"`
	Height                uint64      `boil:"height" json:"height" toml:"height" yaml:"height"`
	MedianTime            uint64      `boil:"median_time" json:"median_time" toml:"median_time" yaml:"median_time"`
	MerkleRoot            string      `boil:"merkle_root" json:"merkle_root" toml:"merkle_root" yaml:"merkle_root"`
	NameClaimRoot         string      `boil:"name_claim_root" json:"name_claim_root" toml:"name_claim_root" yaml:"name_claim_root"`
	Nonce                 uint64      `boil:"nonce" json:"nonce" toml:"nonce" yaml:"nonce"`
	PreviousBlockHash     null.String `boil:"previous_block_hash" json:"previous_block_hash,omitempty" toml:"previous_block_hash" yaml:"previous_block_hash,omitempty"`
	NextBlockHash         null.String `boil:"next_block_hash" json:"next_block_hash,omitempty" toml:"next_block_hash" yaml:"next_block_hash,omitempty"`
	BlockSize             uint64      `boil:"block_size" json:"block_size" toml:"block_size" yaml:"block_size"`
	Target                string      `boil:"target" json:"target" toml:"target" yaml:"target"`
	BlockTime             uint64      `boil:"block_time" json:"block_time" toml:"block_time" yaml:"block_time"`
	Version               uint64      `boil:"version" json:"version" toml:"version" yaml:"version"`
	VersionHex            string      `boil:"version_hex" json:"version_hex" toml:"version_hex" yaml:"version_hex"`
	TransactionHashes     null.String `boil:"transaction_hashes" json:"transaction_hashes,omitempty" toml:"transaction_hashes" yaml:"transaction_hashes,omitempty"`
	TransactionsProcessed bool        `boil:"transactions_processed" json:"transactions_processed" toml:"transactions_processed" yaml:"transactions_processed"`
	Created               time.Time   `boil:"created" json:"created" toml:"created" yaml:"created"`
	Modified              time.Time   `boil:"modified" json:"modified" toml:"modified" yaml:"modified"`

	R *blockR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L blockL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var BlockColumns = struct {
	ID                    string
	Bits                  string
	Chainwork             string
	Confirmations         string
	Difficulty            string
	Hash                  string
	Height                string
	MedianTime            string
	MerkleRoot            string
	NameClaimRoot         string
	Nonce                 string
	PreviousBlockHash     string
	NextBlockHash         string
	BlockSize             string
	Target                string
	BlockTime             string
	Version               string
	VersionHex            string
	TransactionHashes     string
	TransactionsProcessed string
	Created               string
	Modified              string
}{
	ID:                    "id",
	Bits:                  "bits",
	Chainwork:             "chainwork",
	Confirmations:         "confirmations",
	Difficulty:            "difficulty",
	Hash:                  "hash",
	Height:                "height",
	MedianTime:            "median_time",
	MerkleRoot:            "merkle_root",
	NameClaimRoot:         "name_claim_root",
	Nonce:                 "nonce",
	PreviousBlockHash:     "previous_block_hash",
	NextBlockHash:         "next_block_hash",
	BlockSize:             "block_size",
	Target:                "target",
	BlockTime:             "block_time",
	Version:               "version",
	VersionHex:            "version_hex",
	TransactionHashes:     "transaction_hashes",
	TransactionsProcessed: "transactions_processed",
	Created:               "created",
	Modified:              "modified",
}

// blockR is where relationships are stored.
type blockR struct {
	BlockByHashTransactions TransactionSlice
}

// blockL is where Load methods for each relationship are stored.
type blockL struct{}

var (
	blockColumns               = []string{"id", "bits", "chainwork", "confirmations", "difficulty", "hash", "height", "median_time", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "target", "block_time", "version", "version_hex", "transaction_hashes", "transactions_processed", "created", "modified"}
	blockColumnsWithoutDefault = []string{"bits", "chainwork", "confirmations", "difficulty", "hash", "height", "median_time", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "target", "block_time", "version", "version_hex", "transaction_hashes"}
	blockColumnsWithDefault    = []string{"id", "transactions_processed", "created", "modified"}
	blockPrimaryKeyColumns     = []string{"id"}
)

type (
	// BlockSlice is an alias for a slice of pointers to Block.
	// This should generally be used opposed to []Block.
	BlockSlice []*Block

	blockQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	blockType                 = reflect.TypeOf(&Block{})
	blockMapping              = queries.MakeStructMapping(blockType)
	blockPrimaryKeyMapping, _ = queries.BindMapping(blockType, blockMapping, blockPrimaryKeyColumns)
	blockInsertCacheMut       sync.RWMutex
	blockInsertCache          = make(map[string]insertCache)
	blockUpdateCacheMut       sync.RWMutex
	blockUpdateCache          = make(map[string]updateCache)
	blockUpsertCacheMut       sync.RWMutex
	blockUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force bytes in case of primary key column that uses []byte (for relationship compares)
	_ = bytes.MinRead
)

// OneP returns a single block record from the query, and panics on error.
func (q blockQuery) OneP() *Block {
	o, err := q.One()
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// One returns a single block record from the query.
func (q blockQuery) One() (*Block, error) {
	o := &Block{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(o)
	if err != nil {
		if errors.Cause(err) == sql.ErrNoRows {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: failed to execute a one query for blocks")
	}

	return o, nil
}

// AllP returns all Block records from the query, and panics on error.
func (q blockQuery) AllP() BlockSlice {
	o, err := q.All()
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// All returns all Block records from the query.
func (q blockQuery) All() (BlockSlice, error) {
	var o []*Block

	err := q.Bind(&o)
	if err != nil {
		return nil, errors.Wrap(err, "model: failed to assign all query results to Block slice")
	}

	return o, nil
}

// CountP returns the count of all Block records in the query, and panics on error.
func (q blockQuery) CountP() int64 {
	c, err := q.Count()
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return c
}

// Count returns the count of all Block records in the query.
func (q blockQuery) Count() (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRow().Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to count blocks rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table, and panics on error.
func (q blockQuery) ExistsP() bool {
	e, err := q.Exists()
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// Exists checks if the row exists in the table.
func (q blockQuery) Exists() (bool, error) {
	var count int64

	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRow().Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "model: failed to check if blocks exists")
	}

	return count > 0, nil
}

// BlockByHashTransactionsG retrieves all the transaction's transactions via block_by_hash_id column.
func (o *Block) BlockByHashTransactionsG(mods ...qm.QueryMod) transactionQuery {
	return o.BlockByHashTransactions(boil.GetDB(), mods...)
}

// BlockByHashTransactions retrieves all the transaction's transactions with an executor via block_by_hash_id column.
func (o *Block) BlockByHashTransactions(exec boil.Executor, mods ...qm.QueryMod) transactionQuery {
	var queryMods []qm.QueryMod
	if len(mods) != 0 {
		queryMods = append(queryMods, mods...)
	}

	queryMods = append(queryMods,
		qm.Where("`transactions`.`block_by_hash_id`=?", o.Hash),
	)

	query := Transactions(exec, queryMods...)
	queries.SetFrom(query.Query, "`transactions`")

	if len(queries.GetSelect(query.Query)) == 0 {
		queries.SetSelect(query.Query, []string{"`transactions`.*"})
	}

	return query
}

// LoadBlockByHashTransactions allows an eager lookup of values, cached into the
// loaded structs of the objects.
func (blockL) LoadBlockByHashTransactions(e boil.Executor, singular bool, maybeBlock interface{}) error {
	var slice []*Block
	var object *Block

	count := 1
	if singular {
		object = maybeBlock.(*Block)
	} else {
		slice = *maybeBlock.(*[]*Block)
		count = len(slice)
	}

	args := make([]interface{}, count)
	if singular {
		if object.R == nil {
			object.R = &blockR{}
		}
		args[0] = object.Hash
	} else {
		for i, obj := range slice {
			if obj.R == nil {
				obj.R = &blockR{}
			}
			args[i] = obj.Hash
		}
	}

	query := fmt.Sprintf(
		"select * from `transactions` where `block_by_hash_id` in (%s)",
		strmangle.Placeholders(dialect.IndexPlaceholders, count, 1, 1),
	)
	if boil.DebugMode {
		fmt.Fprintf(boil.DebugWriter, "%s\n%v\n", query, args)
	}

	results, err := e.Query(query, args...)
	if err != nil {
		return errors.Wrap(err, "failed to eager load transactions")
	}
	defer results.Close()

	var resultSlice []*Transaction
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice transactions")
	}

	if singular {
		object.R.BlockByHashTransactions = resultSlice
		return nil
	}

	for _, foreign := range resultSlice {
		for _, local := range slice {
			if local.Hash == foreign.BlockByHashID.String {
				local.R.BlockByHashTransactions = append(local.R.BlockByHashTransactions, foreign)
				break
			}
		}
	}

	return nil
}

// AddBlockByHashTransactionsG adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockByHashTransactions.
// Sets related.R.BlockByHash appropriately.
// Uses the global database handle.
func (o *Block) AddBlockByHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.AddBlockByHashTransactions(boil.GetDB(), insert, related...)
}

// AddBlockByHashTransactionsP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockByHashTransactions.
// Sets related.R.BlockByHash appropriately.
// Panics on error.
func (o *Block) AddBlockByHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.AddBlockByHashTransactions(exec, insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// AddBlockByHashTransactionsGP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockByHashTransactions.
// Sets related.R.BlockByHash appropriately.
// Uses the global database handle and panics on error.
func (o *Block) AddBlockByHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.AddBlockByHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// AddBlockByHashTransactions adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockByHashTransactions.
// Sets related.R.BlockByHash appropriately.
func (o *Block) AddBlockByHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		if insert {
			rel.BlockByHashID.String = o.Hash
			rel.BlockByHashID.Valid = true
			if err = rel.Insert(exec); err != nil {
				return errors.Wrap(err, "failed to insert into foreign table")
			}
		} else {
			updateQuery := fmt.Sprintf(
				"UPDATE `transactions` SET %s WHERE %s",
				strmangle.SetParamNames("`", "`", 0, []string{"block_by_hash_id"}),
				strmangle.WhereClause("`", "`", 0, transactionPrimaryKeyColumns),
			)
			values := []interface{}{o.Hash, rel.ID}

			if boil.DebugMode {
				fmt.Fprintln(boil.DebugWriter, updateQuery)
				fmt.Fprintln(boil.DebugWriter, values)
			}

			if _, err = exec.Exec(updateQuery, values...); err != nil {
				return errors.Wrap(err, "failed to update foreign table")
			}

			rel.BlockByHashID.String = o.Hash
			rel.BlockByHashID.Valid = true
		}
	}

	if o.R == nil {
		o.R = &blockR{
			BlockByHashTransactions: related,
		}
	} else {
		o.R.BlockByHashTransactions = append(o.R.BlockByHashTransactions, related...)
	}

	for _, rel := range related {
		if rel.R == nil {
			rel.R = &transactionR{
				BlockByHash: o,
			}
		} else {
			rel.R.BlockByHash = o
		}
	}
	return nil
}

// SetBlockByHashTransactionsG removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockByHash's BlockByHashTransactions accordingly.
// Replaces o.R.BlockByHashTransactions with related.
// Sets related.R.BlockByHash's BlockByHashTransactions accordingly.
// Uses the global database handle.
func (o *Block) SetBlockByHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.SetBlockByHashTransactions(boil.GetDB(), insert, related...)
}

// SetBlockByHashTransactionsP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockByHash's BlockByHashTransactions accordingly.
// Replaces o.R.BlockByHashTransactions with related.
// Sets related.R.BlockByHash's BlockByHashTransactions accordingly.
// Panics on error.
func (o *Block) SetBlockByHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.SetBlockByHashTransactions(exec, insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// SetBlockByHashTransactionsGP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockByHash's BlockByHashTransactions accordingly.
// Replaces o.R.BlockByHashTransactions with related.
// Sets related.R.BlockByHash's BlockByHashTransactions accordingly.
// Uses the global database handle and panics on error.
func (o *Block) SetBlockByHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.SetBlockByHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// SetBlockByHashTransactions removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockByHash's BlockByHashTransactions accordingly.
// Replaces o.R.BlockByHashTransactions with related.
// Sets related.R.BlockByHash's BlockByHashTransactions accordingly.
func (o *Block) SetBlockByHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	query := "update `transactions` set `block_by_hash_id` = null where `block_by_hash_id` = ?"
	values := []interface{}{o.Hash}
	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, query)
		fmt.Fprintln(boil.DebugWriter, values)
	}

	_, err := exec.Exec(query, values...)
	if err != nil {
		return errors.Wrap(err, "failed to remove relationships before set")
	}

	if o.R != nil {
		for _, rel := range o.R.BlockByHashTransactions {
			rel.BlockByHashID.Valid = false
			if rel.R == nil {
				continue
			}

			rel.R.BlockByHash = nil
		}

		o.R.BlockByHashTransactions = nil
	}
	return o.AddBlockByHashTransactions(exec, insert, related...)
}

// RemoveBlockByHashTransactionsG relationships from objects passed in.
// Removes related items from R.BlockByHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockByHash.
// Uses the global database handle.
func (o *Block) RemoveBlockByHashTransactionsG(related ...*Transaction) error {
	return o.RemoveBlockByHashTransactions(boil.GetDB(), related...)
}

// RemoveBlockByHashTransactionsP relationships from objects passed in.
// Removes related items from R.BlockByHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockByHash.
// Panics on error.
func (o *Block) RemoveBlockByHashTransactionsP(exec boil.Executor, related ...*Transaction) {
	if err := o.RemoveBlockByHashTransactions(exec, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// RemoveBlockByHashTransactionsGP relationships from objects passed in.
// Removes related items from R.BlockByHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockByHash.
// Uses the global database handle and panics on error.
func (o *Block) RemoveBlockByHashTransactionsGP(related ...*Transaction) {
	if err := o.RemoveBlockByHashTransactions(boil.GetDB(), related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// RemoveBlockByHashTransactions relationships from objects passed in.
// Removes related items from R.BlockByHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockByHash.
func (o *Block) RemoveBlockByHashTransactions(exec boil.Executor, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		rel.BlockByHashID.Valid = false
		if rel.R != nil {
			rel.R.BlockByHash = nil
		}
		if err = rel.Update(exec, "block_by_hash_id"); err != nil {
			return err
		}
	}
	if o.R == nil {
		return nil
	}

	for _, rel := range related {
		for i, ri := range o.R.BlockByHashTransactions {
			if rel != ri {
				continue
			}

			ln := len(o.R.BlockByHashTransactions)
			if ln > 1 && i < ln-1 {
				o.R.BlockByHashTransactions[i] = o.R.BlockByHashTransactions[ln-1]
			}
			o.R.BlockByHashTransactions = o.R.BlockByHashTransactions[:ln-1]
			break
		}
	}

	return nil
}

// BlocksG retrieves all records.
func BlocksG(mods ...qm.QueryMod) blockQuery {
	return Blocks(boil.GetDB(), mods...)
}

// Blocks retrieves all the records using an executor.
func Blocks(exec boil.Executor, mods ...qm.QueryMod) blockQuery {
	mods = append(mods, qm.From("`blocks`"))
	return blockQuery{NewQuery(exec, mods...)}
}

// FindBlockG retrieves a single record by ID.
func FindBlockG(id uint64, selectCols ...string) (*Block, error) {
	return FindBlock(boil.GetDB(), id, selectCols...)
}

// FindBlockGP retrieves a single record by ID, and panics on error.
func FindBlockGP(id uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(boil.GetDB(), id, selectCols...)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return retobj
}

// FindBlock retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindBlock(exec boil.Executor, id uint64, selectCols ...string) (*Block, error) {
	blockObj := &Block{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from `blocks` where `id`=?", sel,
	)

	q := queries.Raw(exec, query, id)

	err := q.Bind(blockObj)
	if err != nil {
		if errors.Cause(err) == sql.ErrNoRows {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: unable to select from blocks")
	}

	return blockObj, nil
}

// FindBlockP retrieves a single record by ID with an executor, and panics on error.
func FindBlockP(exec boil.Executor, id uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(exec, id, selectCols...)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return retobj
}

// InsertG a single record. See Insert for whitelist behavior description.
func (o *Block) InsertG(whitelist ...string) error {
	return o.Insert(boil.GetDB(), whitelist...)
}

// InsertGP a single record, and panics on error. See Insert for whitelist
// behavior description.
func (o *Block) InsertGP(whitelist ...string) {
	if err := o.Insert(boil.GetDB(), whitelist...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// InsertP a single record using an executor, and panics on error. See Insert
// for whitelist behavior description.
func (o *Block) InsertP(exec boil.Executor, whitelist ...string) {
	if err := o.Insert(exec, whitelist...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Insert a single record using an executor.
// Whitelist behavior: If a whitelist is provided, only those columns supplied are inserted
// No whitelist behavior: Without a whitelist, columns are inferred by the following rules:
// - All columns without a default value are included (i.e. name, age)
// - All columns with a default, but non-zero are included (i.e. health = 75)
func (o *Block) Insert(exec boil.Executor, whitelist ...string) error {
	if o == nil {
		return errors.New("model: no blocks provided for insertion")
	}

	var err error

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)

	key := makeCacheKey(whitelist, nzDefaults)
	blockInsertCacheMut.RLock()
	cache, cached := blockInsertCache[key]
	blockInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := strmangle.InsertColumnSet(
			blockColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
			whitelist,
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(blockType, blockMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO `blocks` (`%s`) %%sVALUES (%s)%%s", strings.Join(wl, "`,`"), strmangle.Placeholders(dialect.IndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO `blocks` () VALUES ()"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT `%s` FROM `blocks` WHERE %s", strings.Join(returnColumns, "`,`"), strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns))
		}

		if len(wl) != 0 {
			cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}

	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "model: unable to insert into blocks")
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["ID"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, identifierCols...)
	}

	err = exec.QueryRow(cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Wrap(err, "model: unable to populate default values for blocks")
	}

CacheNoHooks:
	if !cached {
		blockInsertCacheMut.Lock()
		blockInsertCache[key] = cache
		blockInsertCacheMut.Unlock()
	}

	return nil
}

// UpdateG a single Block record. See Update for
// whitelist behavior description.
func (o *Block) UpdateG(whitelist ...string) error {
	return o.Update(boil.GetDB(), whitelist...)
}

// UpdateGP a single Block record.
// UpdateGP takes a whitelist of column names that should be updated.
// Panics on error. See Update for whitelist behavior description.
func (o *Block) UpdateGP(whitelist ...string) {
	if err := o.Update(boil.GetDB(), whitelist...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateP uses an executor to update the Block, and panics on error.
// See Update for whitelist behavior description.
func (o *Block) UpdateP(exec boil.Executor, whitelist ...string) {
	err := o.Update(exec, whitelist...)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// Update uses an executor to update the Block.
// Whitelist behavior: If a whitelist is provided, only the columns given are updated.
// No whitelist behavior: Without a whitelist, columns are inferred by the following rules:
// - All columns are inferred to start with
// - All primary keys are subtracted from this set
// Update does not automatically update the record in case of default values. Use .Reload()
// to refresh the records.
func (o *Block) Update(exec boil.Executor, whitelist ...string) error {
	var err error
	key := makeCacheKey(whitelist, nil)
	blockUpdateCacheMut.RLock()
	cache, cached := blockUpdateCache[key]
	blockUpdateCacheMut.RUnlock()

	if !cached {
		wl := strmangle.UpdateColumnSet(
			blockColumns,
			blockPrimaryKeyColumns,
			whitelist,
		)

		if len(wl) == 0 {
			return errors.New("model: unable to update blocks, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE `blocks` SET %s WHERE %s",
			strmangle.SetParamNames("`", "`", 0, wl),
			strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, append(wl, blockPrimaryKeyColumns...))
		if err != nil {
			return err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, values)
	}

	_, err = exec.Exec(cache.query, values...)
	if err != nil {
		return errors.Wrap(err, "model: unable to update blocks row")
	}

	if !cached {
		blockUpdateCacheMut.Lock()
		blockUpdateCache[key] = cache
		blockUpdateCacheMut.Unlock()
	}

	return nil
}

// UpdateAllP updates all rows with matching column names, and panics on error.
func (q blockQuery) UpdateAllP(cols M) {
	if err := q.UpdateAll(cols); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAll updates all rows with the specified column values.
func (q blockQuery) UpdateAll(cols M) error {
	queries.SetUpdate(q.Query, cols)

	_, err := q.Query.Exec()
	if err != nil {
		return errors.Wrap(err, "model: unable to update all for blocks")
	}

	return nil
}

// UpdateAllG updates all rows with the specified column values.
func (o BlockSlice) UpdateAllG(cols M) error {
	return o.UpdateAll(boil.GetDB(), cols)
}

// UpdateAllGP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllGP(cols M) {
	if err := o.UpdateAll(boil.GetDB(), cols); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAllP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllP(exec boil.Executor, cols M) {
	if err := o.UpdateAll(exec, cols); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o BlockSlice) UpdateAll(exec boil.Executor, cols M) error {
	ln := int64(len(o))
	if ln == 0 {
		return nil
	}

	if len(cols) == 0 {
		return errors.New("model: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE `blocks` SET %s WHERE %s",
		strmangle.SetParamNames("`", "`", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o)))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to update all in block slice")
	}

	return nil
}

// UpsertG attempts an insert, and does an update or ignore on conflict.
func (o *Block) UpsertG(updateColumns []string, whitelist ...string) error {
	return o.Upsert(boil.GetDB(), updateColumns, whitelist...)
}

// UpsertGP attempts an insert, and does an update or ignore on conflict. Panics on error.
func (o *Block) UpsertGP(updateColumns []string, whitelist ...string) {
	if err := o.Upsert(boil.GetDB(), updateColumns, whitelist...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpsertP attempts an insert using an executor, and does an update or ignore on conflict.
// UpsertP panics on error.
func (o *Block) UpsertP(exec boil.Executor, updateColumns []string, whitelist ...string) {
	if err := o.Upsert(exec, updateColumns, whitelist...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
func (o *Block) Upsert(exec boil.Executor, updateColumns []string, whitelist ...string) error {
	if o == nil {
		return errors.New("model: no blocks provided for upsert")
	}

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs postgres problems
	buf := strmangle.GetBuffer()
	for _, c := range updateColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range whitelist {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	blockUpsertCacheMut.RLock()
	cache, cached := blockUpsertCache[key]
	blockUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, ret := strmangle.InsertColumnSet(
			blockColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
			whitelist,
		)

		update := strmangle.UpdateColumnSet(
			blockColumns,
			blockPrimaryKeyColumns,
			updateColumns,
		)
		if len(update) == 0 {
			return errors.New("model: unable to upsert blocks, could not build update column list")
		}

		cache.query = queries.BuildUpsertQueryMySQL(dialect, "blocks", update, insert)
		cache.retQuery = fmt.Sprintf(
			"SELECT %s FROM `blocks` WHERE `id`=?",
			strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, ret), ","),
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(blockType, blockMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}

	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "model: unable to upsert for blocks")
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["ID"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, identifierCols...)
	}

	err = exec.QueryRow(cache.retQuery, identifierCols...).Scan(returns...)
	if err != nil {
		return errors.Wrap(err, "model: unable to populate default values for blocks")
	}

CacheNoHooks:
	if !cached {
		blockUpsertCacheMut.Lock()
		blockUpsertCache[key] = cache
		blockUpsertCacheMut.Unlock()
	}

	return nil
}

// DeleteP deletes a single Block record with an executor.
// DeleteP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteP(exec boil.Executor) {
	if err := o.Delete(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteG deletes a single Block record.
// DeleteG will match against the primary key column to find the record to delete.
func (o *Block) DeleteG() error {
	if o == nil {
		return errors.New("model: no Block provided for deletion")
	}

	return o.Delete(boil.GetDB())
}

// DeleteGP deletes a single Block record.
// DeleteGP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteGP() {
	if err := o.DeleteG(); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Delete deletes a single Block record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *Block) Delete(exec boil.Executor) error {
	if o == nil {
		return errors.New("model: no Block provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), blockPrimaryKeyMapping)
	sql := "DELETE FROM `blocks` WHERE `id`=?"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete from blocks")
	}

	return nil
}

// DeleteAllP deletes all rows, and panics on error.
func (q blockQuery) DeleteAllP() {
	if err := q.DeleteAll(); err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAll deletes all matching rows.
func (q blockQuery) DeleteAll() error {
	if q.Query == nil {
		return errors.New("model: no blockQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	_, err := q.Query.Exec()
	if err != nil {
		return errors.Wrap(err, "model: unable to delete all from blocks")
	}

	return nil
}

// DeleteAllGP deletes all rows in the slice, and panics on error.
func (o BlockSlice) DeleteAllGP() {
	if err := o.DeleteAllG(); err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAllG deletes all rows in the slice.
func (o BlockSlice) DeleteAllG() error {
	if o == nil {
		return errors.New("model: no Block slice provided for delete all")
	}
	return o.DeleteAll(boil.GetDB())
}

// DeleteAllP deletes all rows in the slice, using an executor, and panics on error.
func (o BlockSlice) DeleteAllP(exec boil.Executor) {
	if err := o.DeleteAll(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o BlockSlice) DeleteAll(exec boil.Executor) error {
	if o == nil {
		return errors.New("model: no Block slice provided for delete all")
	}

	if len(o) == 0 {
		return nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM `blocks` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete all from block slice")
	}

	return nil
}

// ReloadGP refetches the object from the database and panics on error.
func (o *Block) ReloadGP() {
	if err := o.ReloadG(); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadP refetches the object from the database with an executor. Panics on error.
func (o *Block) ReloadP(exec boil.Executor) {
	if err := o.Reload(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadG refetches the object from the database using the primary keys.
func (o *Block) ReloadG() error {
	if o == nil {
		return errors.New("model: no Block provided for reload")
	}

	return o.Reload(boil.GetDB())
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *Block) Reload(exec boil.Executor) error {
	ret, err := FindBlock(exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAllGP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllGP() {
	if err := o.ReloadAllG(); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadAllP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllP(exec boil.Executor) {
	if err := o.ReloadAll(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadAllG refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAllG() error {
	if o == nil {
		return errors.New("model: empty BlockSlice provided for reload all")
	}

	return o.ReloadAll(boil.GetDB())
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAll(exec boil.Executor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	blocks := BlockSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT `blocks`.* FROM `blocks` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(*o))

	q := queries.Raw(exec, sql, args...)

	err := q.Bind(&blocks)
	if err != nil {
		return errors.Wrap(err, "model: unable to reload all in BlockSlice")
	}

	*o = blocks

	return nil
}

// BlockExists checks if the Block row exists.
func BlockExists(exec boil.Executor, id uint64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from `blocks` where `id`=? limit 1)"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, id)
	}

	row := exec.QueryRow(sql, id)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "model: unable to check if blocks exists")
	}

	return exists, nil
}

// BlockExistsG checks if the Block row exists.
func BlockExistsG(id uint64) (bool, error) {
	return BlockExists(boil.GetDB(), id)
}

// BlockExistsGP checks if the Block row exists. Panics on error.
func BlockExistsGP(id uint64) bool {
	e, err := BlockExists(boil.GetDB(), id)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// BlockExistsP checks if the Block row exists. Panics on error.
func BlockExistsP(exec boil.Executor, id uint64) bool {
	e, err := BlockExists(exec, id)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}
