// Code generated by SQLBoiler (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package model

import (
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/pkg/errors"
	"github.com/volatiletech/null"
	"github.com/volatiletech/sqlboiler/boil"
	"github.com/volatiletech/sqlboiler/queries"
	"github.com/volatiletech/sqlboiler/queries/qm"
	"github.com/volatiletech/sqlboiler/queries/qmhelper"
	"github.com/volatiletech/sqlboiler/strmangle"
)

// Block is an object representing the database table.
type Block struct {
	ID                    uint64      `boil:"id" json:"id" toml:"id" yaml:"id"`
	Bits                  string      `boil:"bits" json:"bits" toml:"bits" yaml:"bits"`
	Chainwork             string      `boil:"chainwork" json:"chainwork" toml:"chainwork" yaml:"chainwork"`
	Confirmations         uint        `boil:"confirmations" json:"confirmations" toml:"confirmations" yaml:"confirmations"`
	Difficulty            float64     `boil:"difficulty" json:"difficulty" toml:"difficulty" yaml:"difficulty"`
	Hash                  string      `boil:"hash" json:"hash" toml:"hash" yaml:"hash"`
	Height                uint64      `boil:"height" json:"height" toml:"height" yaml:"height"`
	MerkleRoot            string      `boil:"merkle_root" json:"merkle_root" toml:"merkle_root" yaml:"merkle_root"`
	NameClaimRoot         string      `boil:"name_claim_root" json:"name_claim_root" toml:"name_claim_root" yaml:"name_claim_root"`
	Nonce                 uint64      `boil:"nonce" json:"nonce" toml:"nonce" yaml:"nonce"`
	PreviousBlockHash     null.String `boil:"previous_block_hash" json:"previous_block_hash,omitempty" toml:"previous_block_hash" yaml:"previous_block_hash,omitempty"`
	NextBlockHash         null.String `boil:"next_block_hash" json:"next_block_hash,omitempty" toml:"next_block_hash" yaml:"next_block_hash,omitempty"`
	BlockSize             uint64      `boil:"block_size" json:"block_size" toml:"block_size" yaml:"block_size"`
	BlockTime             uint64      `boil:"block_time" json:"block_time" toml:"block_time" yaml:"block_time"`
	Version               uint64      `boil:"version" json:"version" toml:"version" yaml:"version"`
	VersionHex            string      `boil:"version_hex" json:"version_hex" toml:"version_hex" yaml:"version_hex"`
	TransactionHashes     null.String `boil:"transaction_hashes" json:"transaction_hashes,omitempty" toml:"transaction_hashes" yaml:"transaction_hashes,omitempty"`
	TransactionsProcessed bool        `boil:"transactions_processed" json:"transactions_processed" toml:"transactions_processed" yaml:"transactions_processed"`
	CreatedAt             time.Time   `boil:"created_at" json:"created_at" toml:"created_at" yaml:"created_at"`
	ModifiedAt            time.Time   `boil:"modified_at" json:"modified_at" toml:"modified_at" yaml:"modified_at"`

	R *blockR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L blockL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var BlockColumns = struct {
	ID                    string
	Bits                  string
	Chainwork             string
	Confirmations         string
	Difficulty            string
	Hash                  string
	Height                string
	MerkleRoot            string
	NameClaimRoot         string
	Nonce                 string
	PreviousBlockHash     string
	NextBlockHash         string
	BlockSize             string
	BlockTime             string
	Version               string
	VersionHex            string
	TransactionHashes     string
	TransactionsProcessed string
	CreatedAt             string
	ModifiedAt            string
}{
	ID:                    "id",
	Bits:                  "bits",
	Chainwork:             "chainwork",
	Confirmations:         "confirmations",
	Difficulty:            "difficulty",
	Hash:                  "hash",
	Height:                "height",
	MerkleRoot:            "merkle_root",
	NameClaimRoot:         "name_claim_root",
	Nonce:                 "nonce",
	PreviousBlockHash:     "previous_block_hash",
	NextBlockHash:         "next_block_hash",
	BlockSize:             "block_size",
	BlockTime:             "block_time",
	Version:               "version",
	VersionHex:            "version_hex",
	TransactionHashes:     "transaction_hashes",
	TransactionsProcessed: "transactions_processed",
	CreatedAt:             "created_at",
	ModifiedAt:            "modified_at",
}

// Generated where

var BlockWhere = struct {
	ID                    whereHelperuint64
	Bits                  whereHelperstring
	Chainwork             whereHelperstring
	Confirmations         whereHelperuint
	Difficulty            whereHelperfloat64
	Hash                  whereHelperstring
	Height                whereHelperuint64
	MerkleRoot            whereHelperstring
	NameClaimRoot         whereHelperstring
	Nonce                 whereHelperuint64
	PreviousBlockHash     whereHelpernull_String
	NextBlockHash         whereHelpernull_String
	BlockSize             whereHelperuint64
	BlockTime             whereHelperuint64
	Version               whereHelperuint64
	VersionHex            whereHelperstring
	TransactionHashes     whereHelpernull_String
	TransactionsProcessed whereHelperbool
	CreatedAt             whereHelpertime_Time
	ModifiedAt            whereHelpertime_Time
}{
	ID:                    whereHelperuint64{field: "`block`.`id`"},
	Bits:                  whereHelperstring{field: "`block`.`bits`"},
	Chainwork:             whereHelperstring{field: "`block`.`chainwork`"},
	Confirmations:         whereHelperuint{field: "`block`.`confirmations`"},
	Difficulty:            whereHelperfloat64{field: "`block`.`difficulty`"},
	Hash:                  whereHelperstring{field: "`block`.`hash`"},
	Height:                whereHelperuint64{field: "`block`.`height`"},
	MerkleRoot:            whereHelperstring{field: "`block`.`merkle_root`"},
	NameClaimRoot:         whereHelperstring{field: "`block`.`name_claim_root`"},
	Nonce:                 whereHelperuint64{field: "`block`.`nonce`"},
	PreviousBlockHash:     whereHelpernull_String{field: "`block`.`previous_block_hash`"},
	NextBlockHash:         whereHelpernull_String{field: "`block`.`next_block_hash`"},
	BlockSize:             whereHelperuint64{field: "`block`.`block_size`"},
	BlockTime:             whereHelperuint64{field: "`block`.`block_time`"},
	Version:               whereHelperuint64{field: "`block`.`version`"},
	VersionHex:            whereHelperstring{field: "`block`.`version_hex`"},
	TransactionHashes:     whereHelpernull_String{field: "`block`.`transaction_hashes`"},
	TransactionsProcessed: whereHelperbool{field: "`block`.`transactions_processed`"},
	CreatedAt:             whereHelpertime_Time{field: "`block`.`created_at`"},
	ModifiedAt:            whereHelpertime_Time{field: "`block`.`modified_at`"},
}

// BlockRels is where relationship names are stored.
var BlockRels = struct {
	BlockHashTransactions string
}{
	BlockHashTransactions: "BlockHashTransactions",
}

// blockR is where relationships are stored.
type blockR struct {
	BlockHashTransactions TransactionSlice
}

// NewStruct creates a new relationship struct
func (*blockR) NewStruct() *blockR {
	return &blockR{}
}

// blockL is where Load methods for each relationship are stored.
type blockL struct{}

var (
	blockAllColumns            = []string{"id", "bits", "chainwork", "confirmations", "difficulty", "hash", "height", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "block_time", "version", "version_hex", "transaction_hashes", "transactions_processed", "created_at", "modified_at"}
	blockColumnsWithoutDefault = []string{"bits", "chainwork", "confirmations", "difficulty", "hash", "height", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "block_time", "version", "version_hex", "transaction_hashes"}
	blockColumnsWithDefault    = []string{"id", "transactions_processed", "created_at", "modified_at"}
	blockPrimaryKeyColumns     = []string{"id"}
)

type (
	// BlockSlice is an alias for a slice of pointers to Block.
	// This should generally be used opposed to []Block.
	BlockSlice []*Block

	blockQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	blockType                 = reflect.TypeOf(&Block{})
	blockMapping              = queries.MakeStructMapping(blockType)
	blockPrimaryKeyMapping, _ = queries.BindMapping(blockType, blockMapping, blockPrimaryKeyColumns)
	blockInsertCacheMut       sync.RWMutex
	blockInsertCache          = make(map[string]insertCache)
	blockUpdateCacheMut       sync.RWMutex
	blockUpdateCache          = make(map[string]updateCache)
	blockUpsertCacheMut       sync.RWMutex
	blockUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

// OneG returns a single block record from the query using the global executor.
func (q blockQuery) OneG() (*Block, error) {
	return q.One(boil.GetDB())
}

// OneGP returns a single block record from the query using the global executor, and panics on error.
func (q blockQuery) OneGP() *Block {
	o, err := q.One(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// OneP returns a single block record from the query, and panics on error.
func (q blockQuery) OneP(exec boil.Executor) *Block {
	o, err := q.One(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// One returns a single block record from the query.
func (q blockQuery) One(exec boil.Executor) (*Block, error) {
	o := &Block{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(nil, exec, o)
	if err != nil {
		if errors.Cause(err) == sql.ErrNoRows {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: failed to execute a one query for block")
	}

	return o, nil
}

// AllG returns all Block records from the query using the global executor.
func (q blockQuery) AllG() (BlockSlice, error) {
	return q.All(boil.GetDB())
}

// AllGP returns all Block records from the query using the global executor, and panics on error.
func (q blockQuery) AllGP() BlockSlice {
	o, err := q.All(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// AllP returns all Block records from the query, and panics on error.
func (q blockQuery) AllP(exec boil.Executor) BlockSlice {
	o, err := q.All(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// All returns all Block records from the query.
func (q blockQuery) All(exec boil.Executor) (BlockSlice, error) {
	var o []*Block

	err := q.Bind(nil, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "model: failed to assign all query results to Block slice")
	}

	return o, nil
}

// CountG returns the count of all Block records in the query, and panics on error.
func (q blockQuery) CountG() (int64, error) {
	return q.Count(boil.GetDB())
}

// CountGP returns the count of all Block records in the query using the global executor, and panics on error.
func (q blockQuery) CountGP() int64 {
	c, err := q.Count(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return c
}

// CountP returns the count of all Block records in the query, and panics on error.
func (q blockQuery) CountP(exec boil.Executor) int64 {
	c, err := q.Count(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return c
}

// Count returns the count of all Block records in the query.
func (q blockQuery) Count(exec boil.Executor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRow(exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to count block rows")
	}

	return count, nil
}

// ExistsG checks if the row exists in the table, and panics on error.
func (q blockQuery) ExistsG() (bool, error) {
	return q.Exists(boil.GetDB())
}

// ExistsGP checks if the row exists in the table using the global executor, and panics on error.
func (q blockQuery) ExistsGP() bool {
	e, err := q.Exists(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// ExistsP checks if the row exists in the table, and panics on error.
func (q blockQuery) ExistsP(exec boil.Executor) bool {
	e, err := q.Exists(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// Exists checks if the row exists in the table.
func (q blockQuery) Exists(exec boil.Executor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRow(exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "model: failed to check if block exists")
	}

	return count > 0, nil
}

// BlockHashTransactions retrieves all the transaction's Transactions with an executor via block_hash_id column.
func (o *Block) BlockHashTransactions(mods ...qm.QueryMod) transactionQuery {
	var queryMods []qm.QueryMod
	if len(mods) != 0 {
		queryMods = append(queryMods, mods...)
	}

	queryMods = append(queryMods,
		qm.Where("`transaction`.`block_hash_id`=?", o.Hash),
	)

	query := Transactions(queryMods...)
	queries.SetFrom(query.Query, "`transaction`")

	if len(queries.GetSelect(query.Query)) == 0 {
		queries.SetSelect(query.Query, []string{"`transaction`.*"})
	}

	return query
}

// LoadBlockHashTransactions allows an eager lookup of values, cached into the
// loaded structs of the objects. This is for a 1-M or N-M relationship.
func (blockL) LoadBlockHashTransactions(e boil.Executor, singular bool, maybeBlock interface{}, mods queries.Applicator) error {
	var slice []*Block
	var object *Block

	if singular {
		object = maybeBlock.(*Block)
	} else {
		slice = *maybeBlock.(*[]*Block)
	}

	args := make([]interface{}, 0, 1)
	if singular {
		if object.R == nil {
			object.R = &blockR{}
		}
		args = append(args, object.Hash)
	} else {
	Outer:
		for _, obj := range slice {
			if obj.R == nil {
				obj.R = &blockR{}
			}

			for _, a := range args {
				if queries.Equal(a, obj.Hash) {
					continue Outer
				}
			}

			args = append(args, obj.Hash)
		}
	}

	if len(args) == 0 {
		return nil
	}

	query := NewQuery(qm.From(`transaction`), qm.WhereIn(`block_hash_id in ?`, args...))
	if mods != nil {
		mods.Apply(query)
	}

	results, err := query.Query(e)
	if err != nil {
		return errors.Wrap(err, "failed to eager load transaction")
	}

	var resultSlice []*Transaction
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice transaction")
	}

	if err = results.Close(); err != nil {
		return errors.Wrap(err, "failed to close results in eager load on transaction")
	}
	if err = results.Err(); err != nil {
		return errors.Wrap(err, "error occurred during iteration of eager loaded relations for transaction")
	}

	if singular {
		object.R.BlockHashTransactions = resultSlice
		for _, foreign := range resultSlice {
			if foreign.R == nil {
				foreign.R = &transactionR{}
			}
			foreign.R.BlockHash = object
		}
		return nil
	}

	for _, foreign := range resultSlice {
		for _, local := range slice {
			if queries.Equal(local.Hash, foreign.BlockHashID) {
				local.R.BlockHashTransactions = append(local.R.BlockHashTransactions, foreign)
				if foreign.R == nil {
					foreign.R = &transactionR{}
				}
				foreign.R.BlockHash = local
				break
			}
		}
	}

	return nil
}

// AddBlockHashTransactionsG adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Uses the global database handle.
func (o *Block) AddBlockHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.AddBlockHashTransactions(boil.GetDB(), insert, related...)
}

// AddBlockHashTransactionsP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Panics on error.
func (o *Block) AddBlockHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.AddBlockHashTransactions(exec, insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// AddBlockHashTransactionsGP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Uses the global database handle and panics on error.
func (o *Block) AddBlockHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.AddBlockHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// AddBlockHashTransactions adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
func (o *Block) AddBlockHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		if insert {
			queries.Assign(&rel.BlockHashID, o.Hash)
			if err = rel.Insert(exec, boil.Infer()); err != nil {
				return errors.Wrap(err, "failed to insert into foreign table")
			}
		} else {
			updateQuery := fmt.Sprintf(
				"UPDATE `transaction` SET %s WHERE %s",
				strmangle.SetParamNames("`", "`", 0, []string{"block_hash_id"}),
				strmangle.WhereClause("`", "`", 0, transactionPrimaryKeyColumns),
			)
			values := []interface{}{o.Hash, rel.ID}

			if boil.DebugMode {
				fmt.Fprintln(boil.DebugWriter, updateQuery)
				fmt.Fprintln(boil.DebugWriter, values)
			}

			if _, err = exec.Exec(updateQuery, values...); err != nil {
				return errors.Wrap(err, "failed to update foreign table")
			}

			queries.Assign(&rel.BlockHashID, o.Hash)
		}
	}

	if o.R == nil {
		o.R = &blockR{
			BlockHashTransactions: related,
		}
	} else {
		o.R.BlockHashTransactions = append(o.R.BlockHashTransactions, related...)
	}

	for _, rel := range related {
		if rel.R == nil {
			rel.R = &transactionR{
				BlockHash: o,
			}
		} else {
			rel.R.BlockHash = o
		}
	}
	return nil
}

// SetBlockHashTransactionsG removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Uses the global database handle.
func (o *Block) SetBlockHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.SetBlockHashTransactions(boil.GetDB(), insert, related...)
}

// SetBlockHashTransactionsP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Panics on error.
func (o *Block) SetBlockHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.SetBlockHashTransactions(exec, insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// SetBlockHashTransactionsGP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Uses the global database handle and panics on error.
func (o *Block) SetBlockHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.SetBlockHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// SetBlockHashTransactions removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
func (o *Block) SetBlockHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	query := "update `transaction` set `block_hash_id` = null where `block_hash_id` = ?"
	values := []interface{}{o.Hash}
	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, query)
		fmt.Fprintln(boil.DebugWriter, values)
	}

	_, err := exec.Exec(query, values...)
	if err != nil {
		return errors.Wrap(err, "failed to remove relationships before set")
	}

	if o.R != nil {
		for _, rel := range o.R.BlockHashTransactions {
			queries.SetScanner(&rel.BlockHashID, nil)
			if rel.R == nil {
				continue
			}

			rel.R.BlockHash = nil
		}

		o.R.BlockHashTransactions = nil
	}
	return o.AddBlockHashTransactions(exec, insert, related...)
}

// RemoveBlockHashTransactionsG relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Uses the global database handle.
func (o *Block) RemoveBlockHashTransactionsG(related ...*Transaction) error {
	return o.RemoveBlockHashTransactions(boil.GetDB(), related...)
}

// RemoveBlockHashTransactionsP relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Panics on error.
func (o *Block) RemoveBlockHashTransactionsP(exec boil.Executor, related ...*Transaction) {
	if err := o.RemoveBlockHashTransactions(exec, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// RemoveBlockHashTransactionsGP relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Uses the global database handle and panics on error.
func (o *Block) RemoveBlockHashTransactionsGP(related ...*Transaction) {
	if err := o.RemoveBlockHashTransactions(boil.GetDB(), related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// RemoveBlockHashTransactions relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
func (o *Block) RemoveBlockHashTransactions(exec boil.Executor, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		queries.SetScanner(&rel.BlockHashID, nil)
		if rel.R != nil {
			rel.R.BlockHash = nil
		}
		if err = rel.Update(exec, boil.Whitelist("block_hash_id")); err != nil {
			return err
		}
	}
	if o.R == nil {
		return nil
	}

	for _, rel := range related {
		for i, ri := range o.R.BlockHashTransactions {
			if rel != ri {
				continue
			}

			ln := len(o.R.BlockHashTransactions)
			if ln > 1 && i < ln-1 {
				o.R.BlockHashTransactions[i] = o.R.BlockHashTransactions[ln-1]
			}
			o.R.BlockHashTransactions = o.R.BlockHashTransactions[:ln-1]
			break
		}
	}

	return nil
}

// Blocks retrieves all the records using an executor.
func Blocks(mods ...qm.QueryMod) blockQuery {
	mods = append(mods, qm.From("`block`"))
	return blockQuery{NewQuery(mods...)}
}

// FindBlockG retrieves a single record by ID.
func FindBlockG(iD uint64, selectCols ...string) (*Block, error) {
	return FindBlock(boil.GetDB(), iD, selectCols...)
}

// FindBlockP retrieves a single record by ID with an executor, and panics on error.
func FindBlockP(exec boil.Executor, iD uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(exec, iD, selectCols...)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return retobj
}

// FindBlockGP retrieves a single record by ID, and panics on error.
func FindBlockGP(iD uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(boil.GetDB(), iD, selectCols...)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return retobj
}

// FindBlock retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindBlock(exec boil.Executor, iD uint64, selectCols ...string) (*Block, error) {
	blockObj := &Block{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from `block` where `id`=?", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(nil, exec, blockObj)
	if err != nil {
		if errors.Cause(err) == sql.ErrNoRows {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: unable to select from block")
	}

	return blockObj, nil
}

// InsertG a single record. See Insert for whitelist behavior description.
func (o *Block) InsertG(columns boil.Columns) error {
	return o.Insert(boil.GetDB(), columns)
}

// InsertP a single record using an executor, and panics on error. See Insert
// for whitelist behavior description.
func (o *Block) InsertP(exec boil.Executor, columns boil.Columns) {
	if err := o.Insert(exec, columns); err != nil {
		panic(boil.WrapErr(err))
	}
}

// InsertGP a single record, and panics on error. See Insert for whitelist
// behavior description.
func (o *Block) InsertGP(columns boil.Columns) {
	if err := o.Insert(boil.GetDB(), columns); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *Block) Insert(exec boil.Executor, columns boil.Columns) error {
	if o == nil {
		return errors.New("model: no block provided for insertion")
	}

	var err error

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	blockInsertCacheMut.RLock()
	cache, cached := blockInsertCache[key]
	blockInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			blockAllColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(blockType, blockMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO `block` (`%s`) %%sVALUES (%s)%%s", strings.Join(wl, "`,`"), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO `block` () VALUES ()%s%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT `%s` FROM `block` WHERE %s", strings.Join(returnColumns, "`,`"), strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}

	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "model: unable to insert into block")
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["ID"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, identifierCols...)
	}

	err = exec.QueryRow(cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Wrap(err, "model: unable to populate default values for block")
	}

CacheNoHooks:
	if !cached {
		blockInsertCacheMut.Lock()
		blockInsertCache[key] = cache
		blockInsertCacheMut.Unlock()
	}

	return nil
}

// UpdateG a single Block record using the global executor.
// See Update for more documentation.
func (o *Block) UpdateG(columns boil.Columns) error {
	return o.Update(boil.GetDB(), columns)
}

// UpdateP uses an executor to update the Block, and panics on error.
// See Update for more documentation.
func (o *Block) UpdateP(exec boil.Executor, columns boil.Columns) {
	err := o.Update(exec, columns)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateGP a single Block record using the global executor. Panics on error.
// See Update for more documentation.
func (o *Block) UpdateGP(columns boil.Columns) {
	err := o.Update(boil.GetDB(), columns)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// Update uses an executor to update the Block.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *Block) Update(exec boil.Executor, columns boil.Columns) error {
	var err error
	key := makeCacheKey(columns, nil)
	blockUpdateCacheMut.RLock()
	cache, cached := blockUpdateCache[key]
	blockUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			blockAllColumns,
			blockPrimaryKeyColumns,
		)

		if len(wl) == 0 {
			return errors.New("model: unable to update block, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE `block` SET %s WHERE %s",
			strmangle.SetParamNames("`", "`", 0, wl),
			strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, append(wl, blockPrimaryKeyColumns...))
		if err != nil {
			return err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, values)
	}

	_, err = exec.Exec(cache.query, values...)
	if err != nil {
		return errors.Wrap(err, "model: unable to update block row")
	}

	if !cached {
		blockUpdateCacheMut.Lock()
		blockUpdateCache[key] = cache
		blockUpdateCacheMut.Unlock()
	}

	return nil
}

// UpdateAllP updates all rows with matching column names, and panics on error.
func (q blockQuery) UpdateAllP(exec boil.Executor, cols M) {
	err := q.UpdateAll(exec, cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAllG updates all rows with the specified column values.
func (q blockQuery) UpdateAllG(cols M) error {
	return q.UpdateAll(boil.GetDB(), cols)
}

// UpdateAll updates all rows with the specified column values.
func (q blockQuery) UpdateAll(exec boil.Executor, cols M) error {
	queries.SetUpdate(q.Query, cols)

	_, err := q.Query.Exec(exec)
	if err != nil {
		return errors.Wrap(err, "model: unable to update all for block")
	}

	return nil
}

// UpdateAllG updates all rows with the specified column values.
func (o BlockSlice) UpdateAllG(cols M) error {
	return o.UpdateAll(boil.GetDB(), cols)
}

// UpdateAllGP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllGP(cols M) {
	err := o.UpdateAll(boil.GetDB(), cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAllP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllP(exec boil.Executor, cols M) {
	err := o.UpdateAll(exec, cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o BlockSlice) UpdateAll(exec boil.Executor, cols M) error {
	ln := int64(len(o))
	if ln == 0 {
		return nil
	}

	if len(cols) == 0 {
		return errors.New("model: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE `block` SET %s WHERE %s",
		strmangle.SetParamNames("`", "`", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o)))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to update all in block slice")
	}

	return nil
}

// UpsertG attempts an insert, and does an update or ignore on conflict.
func (o *Block) UpsertG(updateColumns, insertColumns boil.Columns) error {
	return o.Upsert(boil.GetDB(), updateColumns, insertColumns)
}

// UpsertGP attempts an insert, and does an update or ignore on conflict. Panics on error.
func (o *Block) UpsertGP(updateColumns, insertColumns boil.Columns) {
	if err := o.Upsert(boil.GetDB(), updateColumns, insertColumns); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpsertP attempts an insert using an executor, and does an update or ignore on conflict.
// UpsertP panics on error.
func (o *Block) UpsertP(exec boil.Executor, updateColumns, insertColumns boil.Columns) {
	if err := o.Upsert(exec, updateColumns, insertColumns); err != nil {
		panic(boil.WrapErr(err))
	}
}

var mySQLBlockUniqueColumns = []string{
	"id",
	"hash",
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *Block) Upsert(exec boil.Executor, updateColumns, insertColumns boil.Columns) error {
	if o == nil {
		return errors.New("model: no block provided for upsert")
	}

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)
	nzUniques := queries.NonZeroDefaultSet(mySQLBlockUniqueColumns, o)

	if len(nzUniques) == 0 {
		return errors.New("cannot upsert with a table that cannot conflict on a unique column")
	}

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzUniques {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	blockUpsertCacheMut.RLock()
	cache, cached := blockUpsertCache[key]
	blockUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, ret := insertColumns.InsertColumnSet(
			blockAllColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
		)
		update := updateColumns.UpdateColumnSet(
			blockAllColumns,
			blockPrimaryKeyColumns,
		)

		if len(update) == 0 {
			return errors.New("model: unable to upsert block, could not build update column list")
		}

		ret = strmangle.SetComplement(ret, nzUniques)
		cache.query = buildUpsertQueryMySQL(dialect, "block", update, insert)
		cache.retQuery = fmt.Sprintf(
			"SELECT %s FROM `block` WHERE %s",
			strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, ret), ","),
			strmangle.WhereClause("`", "`", 0, nzUniques),
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(blockType, blockMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}

	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "model: unable to upsert for block")
	}

	var lastID int64
	var uniqueMap []uint64
	var nzUniqueCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["id"] {
		goto CacheNoHooks
	}

	uniqueMap, err = queries.BindMapping(blockType, blockMapping, nzUniques)
	if err != nil {
		return errors.Wrap(err, "model: unable to retrieve unique values for block")
	}
	nzUniqueCols = queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), uniqueMap)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, nzUniqueCols...)
	}

	err = exec.QueryRow(cache.retQuery, nzUniqueCols...).Scan(returns...)
	if err != nil {
		return errors.Wrap(err, "model: unable to populate default values for block")
	}

CacheNoHooks:
	if !cached {
		blockUpsertCacheMut.Lock()
		blockUpsertCache[key] = cache
		blockUpsertCacheMut.Unlock()
	}

	return nil
}

// DeleteG deletes a single Block record.
// DeleteG will match against the primary key column to find the record to delete.
func (o *Block) DeleteG() error {
	return o.Delete(boil.GetDB())
}

// DeleteP deletes a single Block record with an executor.
// DeleteP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteP(exec boil.Executor) {
	err := o.Delete(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteGP deletes a single Block record.
// DeleteGP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteGP() {
	err := o.Delete(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// Delete deletes a single Block record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *Block) Delete(exec boil.Executor) error {
	if o == nil {
		return errors.New("model: no Block provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), blockPrimaryKeyMapping)
	sql := "DELETE FROM `block` WHERE `id`=?"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete from block")
	}

	return nil
}

// DeleteAllP deletes all rows, and panics on error.
func (q blockQuery) DeleteAllP(exec boil.Executor) {
	err := q.DeleteAll(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAll deletes all matching rows.
func (q blockQuery) DeleteAll(exec boil.Executor) error {
	if q.Query == nil {
		return errors.New("model: no blockQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	_, err := q.Query.Exec(exec)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete all from block")
	}

	return nil
}

// DeleteAllG deletes all rows in the slice.
func (o BlockSlice) DeleteAllG() error {
	return o.DeleteAll(boil.GetDB())
}

// DeleteAllP deletes all rows in the slice, using an executor, and panics on error.
func (o BlockSlice) DeleteAllP(exec boil.Executor) {
	err := o.DeleteAll(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAllGP deletes all rows in the slice, and panics on error.
func (o BlockSlice) DeleteAllGP() {
	err := o.DeleteAll(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o BlockSlice) DeleteAll(exec boil.Executor) error {
	if len(o) == 0 {
		return nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM `block` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args)
	}

	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete all from block slice")
	}

	return nil
}

// ReloadG refetches the object from the database using the primary keys.
func (o *Block) ReloadG() error {
	if o == nil {
		return errors.New("model: no Block provided for reload")
	}

	return o.Reload(boil.GetDB())
}

// ReloadP refetches the object from the database with an executor. Panics on error.
func (o *Block) ReloadP(exec boil.Executor) {
	if err := o.Reload(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadGP refetches the object from the database and panics on error.
func (o *Block) ReloadGP() {
	if err := o.Reload(boil.GetDB()); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *Block) Reload(exec boil.Executor) error {
	ret, err := FindBlock(exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAllG refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAllG() error {
	if o == nil {
		return errors.New("model: empty BlockSlice provided for reload all")
	}

	return o.ReloadAll(boil.GetDB())
}

// ReloadAllP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllP(exec boil.Executor) {
	if err := o.ReloadAll(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadAllGP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllGP() {
	if err := o.ReloadAll(boil.GetDB()); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAll(exec boil.Executor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := BlockSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT `block`.* FROM `block` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(nil, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "model: unable to reload all in BlockSlice")
	}

	*o = slice

	return nil
}

// BlockExistsG checks if the Block row exists.
func BlockExistsG(iD uint64) (bool, error) {
	return BlockExists(boil.GetDB(), iD)
}

// BlockExistsP checks if the Block row exists. Panics on error.
func BlockExistsP(exec boil.Executor, iD uint64) bool {
	e, err := BlockExists(exec, iD)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// BlockExistsGP checks if the Block row exists. Panics on error.
func BlockExistsGP(iD uint64) bool {
	e, err := BlockExists(boil.GetDB(), iD)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// BlockExists checks if the Block row exists.
func BlockExists(exec boil.Executor, iD uint64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from `block` where `id`=? limit 1)"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, iD)
	}

	row := exec.QueryRow(sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "model: unable to check if block exists")
	}

	return exists, nil
}
