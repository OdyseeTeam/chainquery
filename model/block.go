// Code generated by SQLBoiler 4.10.2 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package model

import (
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/null/v8"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/strmangle"
)

// Block is an object representing the database table.
type Block struct {
	ID                uint64      `boil:"id" json:"id" toml:"id" yaml:"id"`
	Bits              string      `boil:"bits" json:"bits" toml:"bits" yaml:"bits"`
	Chainwork         string      `boil:"chainwork" json:"chainwork" toml:"chainwork" yaml:"chainwork"`
	Confirmations     uint        `boil:"confirmations" json:"confirmations" toml:"confirmations" yaml:"confirmations"`
	Difficulty        float64     `boil:"difficulty" json:"difficulty" toml:"difficulty" yaml:"difficulty"`
	Hash              string      `boil:"hash" json:"hash" toml:"hash" yaml:"hash"`
	Height            uint64      `boil:"height" json:"height" toml:"height" yaml:"height"`
	MerkleRoot        string      `boil:"merkle_root" json:"merkle_root" toml:"merkle_root" yaml:"merkle_root"`
	NameClaimRoot     string      `boil:"name_claim_root" json:"name_claim_root" toml:"name_claim_root" yaml:"name_claim_root"`
	Nonce             uint64      `boil:"nonce" json:"nonce" toml:"nonce" yaml:"nonce"`
	PreviousBlockHash null.String `boil:"previous_block_hash" json:"previous_block_hash,omitempty" toml:"previous_block_hash" yaml:"previous_block_hash,omitempty"`
	NextBlockHash     null.String `boil:"next_block_hash" json:"next_block_hash,omitempty" toml:"next_block_hash" yaml:"next_block_hash,omitempty"`
	BlockSize         uint64      `boil:"block_size" json:"block_size" toml:"block_size" yaml:"block_size"`
	BlockTime         uint64      `boil:"block_time" json:"block_time" toml:"block_time" yaml:"block_time"`
	Version           uint64      `boil:"version" json:"version" toml:"version" yaml:"version"`
	VersionHex        string      `boil:"version_hex" json:"version_hex" toml:"version_hex" yaml:"version_hex"`
	CreatedAt         time.Time   `boil:"created_at" json:"created_at" toml:"created_at" yaml:"created_at"`
	ModifiedAt        time.Time   `boil:"modified_at" json:"modified_at" toml:"modified_at" yaml:"modified_at"`

	R *blockR `boil:"-" json:"-" toml:"-" yaml:"-"`
	L blockL  `boil:"-" json:"-" toml:"-" yaml:"-"`
}

var BlockColumns = struct {
	ID                string
	Bits              string
	Chainwork         string
	Confirmations     string
	Difficulty        string
	Hash              string
	Height            string
	MerkleRoot        string
	NameClaimRoot     string
	Nonce             string
	PreviousBlockHash string
	NextBlockHash     string
	BlockSize         string
	BlockTime         string
	Version           string
	VersionHex        string
	CreatedAt         string
	ModifiedAt        string
}{
	ID:                "id",
	Bits:              "bits",
	Chainwork:         "chainwork",
	Confirmations:     "confirmations",
	Difficulty:        "difficulty",
	Hash:              "hash",
	Height:            "height",
	MerkleRoot:        "merkle_root",
	NameClaimRoot:     "name_claim_root",
	Nonce:             "nonce",
	PreviousBlockHash: "previous_block_hash",
	NextBlockHash:     "next_block_hash",
	BlockSize:         "block_size",
	BlockTime:         "block_time",
	Version:           "version",
	VersionHex:        "version_hex",
	CreatedAt:         "created_at",
	ModifiedAt:        "modified_at",
}

var BlockTableColumns = struct {
	ID                string
	Bits              string
	Chainwork         string
	Confirmations     string
	Difficulty        string
	Hash              string
	Height            string
	MerkleRoot        string
	NameClaimRoot     string
	Nonce             string
	PreviousBlockHash string
	NextBlockHash     string
	BlockSize         string
	BlockTime         string
	Version           string
	VersionHex        string
	CreatedAt         string
	ModifiedAt        string
}{
	ID:                "block.id",
	Bits:              "block.bits",
	Chainwork:         "block.chainwork",
	Confirmations:     "block.confirmations",
	Difficulty:        "block.difficulty",
	Hash:              "block.hash",
	Height:            "block.height",
	MerkleRoot:        "block.merkle_root",
	NameClaimRoot:     "block.name_claim_root",
	Nonce:             "block.nonce",
	PreviousBlockHash: "block.previous_block_hash",
	NextBlockHash:     "block.next_block_hash",
	BlockSize:         "block.block_size",
	BlockTime:         "block.block_time",
	Version:           "block.version",
	VersionHex:        "block.version_hex",
	CreatedAt:         "block.created_at",
	ModifiedAt:        "block.modified_at",
}

// Generated where

var BlockWhere = struct {
	ID                whereHelperuint64
	Bits              whereHelperstring
	Chainwork         whereHelperstring
	Confirmations     whereHelperuint
	Difficulty        whereHelperfloat64
	Hash              whereHelperstring
	Height            whereHelperuint64
	MerkleRoot        whereHelperstring
	NameClaimRoot     whereHelperstring
	Nonce             whereHelperuint64
	PreviousBlockHash whereHelpernull_String
	NextBlockHash     whereHelpernull_String
	BlockSize         whereHelperuint64
	BlockTime         whereHelperuint64
	Version           whereHelperuint64
	VersionHex        whereHelperstring
	CreatedAt         whereHelpertime_Time
	ModifiedAt        whereHelpertime_Time
}{
	ID:                whereHelperuint64{field: "`block`.`id`"},
	Bits:              whereHelperstring{field: "`block`.`bits`"},
	Chainwork:         whereHelperstring{field: "`block`.`chainwork`"},
	Confirmations:     whereHelperuint{field: "`block`.`confirmations`"},
	Difficulty:        whereHelperfloat64{field: "`block`.`difficulty`"},
	Hash:              whereHelperstring{field: "`block`.`hash`"},
	Height:            whereHelperuint64{field: "`block`.`height`"},
	MerkleRoot:        whereHelperstring{field: "`block`.`merkle_root`"},
	NameClaimRoot:     whereHelperstring{field: "`block`.`name_claim_root`"},
	Nonce:             whereHelperuint64{field: "`block`.`nonce`"},
	PreviousBlockHash: whereHelpernull_String{field: "`block`.`previous_block_hash`"},
	NextBlockHash:     whereHelpernull_String{field: "`block`.`next_block_hash`"},
	BlockSize:         whereHelperuint64{field: "`block`.`block_size`"},
	BlockTime:         whereHelperuint64{field: "`block`.`block_time`"},
	Version:           whereHelperuint64{field: "`block`.`version`"},
	VersionHex:        whereHelperstring{field: "`block`.`version_hex`"},
	CreatedAt:         whereHelpertime_Time{field: "`block`.`created_at`"},
	ModifiedAt:        whereHelpertime_Time{field: "`block`.`modified_at`"},
}

// BlockRels is where relationship names are stored.
var BlockRels = struct {
	BlockHashTransactions string
}{
	BlockHashTransactions: "BlockHashTransactions",
}

// blockR is where relationships are stored.
type blockR struct {
	BlockHashTransactions TransactionSlice `boil:"BlockHashTransactions" json:"BlockHashTransactions" toml:"BlockHashTransactions" yaml:"BlockHashTransactions"`
}

// NewStruct creates a new relationship struct
func (*blockR) NewStruct() *blockR {
	return &blockR{}
}

// blockL is where Load methods for each relationship are stored.
type blockL struct{}

var (
	blockAllColumns            = []string{"id", "bits", "chainwork", "confirmations", "difficulty", "hash", "height", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "block_time", "version", "version_hex", "created_at", "modified_at"}
	blockColumnsWithoutDefault = []string{"bits", "chainwork", "confirmations", "difficulty", "hash", "height", "merkle_root", "name_claim_root", "nonce", "previous_block_hash", "next_block_hash", "block_size", "block_time", "version", "version_hex"}
	blockColumnsWithDefault    = []string{"id", "created_at", "modified_at"}
	blockPrimaryKeyColumns     = []string{"id"}
	blockGeneratedColumns      = []string{}
)

type (
	// BlockSlice is an alias for a slice of pointers to Block.
	// This should almost always be used instead of []Block.
	BlockSlice []*Block

	blockQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	blockType                 = reflect.TypeOf(&Block{})
	blockMapping              = queries.MakeStructMapping(blockType)
	blockPrimaryKeyMapping, _ = queries.BindMapping(blockType, blockMapping, blockPrimaryKeyColumns)
	blockInsertCacheMut       sync.RWMutex
	blockInsertCache          = make(map[string]insertCache)
	blockUpdateCacheMut       sync.RWMutex
	blockUpdateCache          = make(map[string]updateCache)
	blockUpsertCacheMut       sync.RWMutex
	blockUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

// OneG returns a single block record from the query using the global executor.
func (q blockQuery) OneG() (*Block, error) {
	return q.One(boil.GetDB())
}

// OneGP returns a single block record from the query using the global executor, and panics on error.
func (q blockQuery) OneGP() *Block {
	o, err := q.One(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// OneP returns a single block record from the query, and panics on error.
func (q blockQuery) OneP(exec boil.Executor) *Block {
	o, err := q.One(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// One returns a single block record from the query.
func (q blockQuery) One(exec boil.Executor) (*Block, error) {
	o := &Block{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(nil, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: failed to execute a one query for block")
	}

	return o, nil
}

// AllG returns all Block records from the query using the global executor.
func (q blockQuery) AllG() (BlockSlice, error) {
	return q.All(boil.GetDB())
}

// AllGP returns all Block records from the query using the global executor, and panics on error.
func (q blockQuery) AllGP() BlockSlice {
	o, err := q.All(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// AllP returns all Block records from the query, and panics on error.
func (q blockQuery) AllP(exec boil.Executor) BlockSlice {
	o, err := q.All(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return o
}

// All returns all Block records from the query.
func (q blockQuery) All(exec boil.Executor) (BlockSlice, error) {
	var o []*Block

	err := q.Bind(nil, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "model: failed to assign all query results to Block slice")
	}

	return o, nil
}

// CountG returns the count of all Block records in the query using the global executor
func (q blockQuery) CountG() (int64, error) {
	return q.Count(boil.GetDB())
}

// CountGP returns the count of all Block records in the query using the global executor, and panics on error.
func (q blockQuery) CountGP() int64 {
	c, err := q.Count(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return c
}

// CountP returns the count of all Block records in the query, and panics on error.
func (q blockQuery) CountP(exec boil.Executor) int64 {
	c, err := q.Count(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return c
}

// Count returns the count of all Block records in the query.
func (q blockQuery) Count(exec boil.Executor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRow(exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to count block rows")
	}

	return count, nil
}

// ExistsG checks if the row exists in the table using the global executor.
func (q blockQuery) ExistsG() (bool, error) {
	return q.Exists(boil.GetDB())
}

// ExistsGP checks if the row exists in the table using the global executor, and panics on error.
func (q blockQuery) ExistsGP() bool {
	e, err := q.Exists(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// ExistsP checks if the row exists in the table, and panics on error.
func (q blockQuery) ExistsP(exec boil.Executor) bool {
	e, err := q.Exists(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// Exists checks if the row exists in the table.
func (q blockQuery) Exists(exec boil.Executor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRow(exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "model: failed to check if block exists")
	}

	return count > 0, nil
}

// BlockHashTransactions retrieves all the transaction's Transactions with an executor via block_hash_id column.
func (o *Block) BlockHashTransactions(mods ...qm.QueryMod) transactionQuery {
	var queryMods []qm.QueryMod
	if len(mods) != 0 {
		queryMods = append(queryMods, mods...)
	}

	queryMods = append(queryMods,
		qm.Where("`transaction`.`block_hash_id`=?", o.Hash),
	)

	return Transactions(queryMods...)
}

// LoadBlockHashTransactions allows an eager lookup of values, cached into the
// loaded structs of the objects. This is for a 1-M or N-M relationship.
func (blockL) LoadBlockHashTransactions(e boil.Executor, singular bool, maybeBlock interface{}, mods queries.Applicator) error {
	var slice []*Block
	var object *Block

	if singular {
		object = maybeBlock.(*Block)
	} else {
		slice = *maybeBlock.(*[]*Block)
	}

	args := make([]interface{}, 0, 1)
	if singular {
		if object.R == nil {
			object.R = &blockR{}
		}
		args = append(args, object.Hash)
	} else {
	Outer:
		for _, obj := range slice {
			if obj.R == nil {
				obj.R = &blockR{}
			}

			for _, a := range args {
				if queries.Equal(a, obj.Hash) {
					continue Outer
				}
			}

			args = append(args, obj.Hash)
		}
	}

	if len(args) == 0 {
		return nil
	}

	query := NewQuery(
		qm.From(`transaction`),
		qm.WhereIn(`transaction.block_hash_id in ?`, args...),
	)
	if mods != nil {
		mods.Apply(query)
	}

	results, err := query.Query(e)
	if err != nil {
		return errors.Wrap(err, "failed to eager load transaction")
	}

	var resultSlice []*Transaction
	if err = queries.Bind(results, &resultSlice); err != nil {
		return errors.Wrap(err, "failed to bind eager loaded slice transaction")
	}

	if err = results.Close(); err != nil {
		return errors.Wrap(err, "failed to close results in eager load on transaction")
	}
	if err = results.Err(); err != nil {
		return errors.Wrap(err, "error occurred during iteration of eager loaded relations for transaction")
	}

	if singular {
		object.R.BlockHashTransactions = resultSlice
		for _, foreign := range resultSlice {
			if foreign.R == nil {
				foreign.R = &transactionR{}
			}
			foreign.R.BlockHash = object
		}
		return nil
	}

	for _, foreign := range resultSlice {
		for _, local := range slice {
			if queries.Equal(local.Hash, foreign.BlockHashID) {
				local.R.BlockHashTransactions = append(local.R.BlockHashTransactions, foreign)
				if foreign.R == nil {
					foreign.R = &transactionR{}
				}
				foreign.R.BlockHash = local
				break
			}
		}
	}

	return nil
}

// AddBlockHashTransactionsG adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Uses the global database handle.
func (o *Block) AddBlockHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.AddBlockHashTransactions(boil.GetDB(), insert, related...)
}

// AddBlockHashTransactionsP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Panics on error.
func (o *Block) AddBlockHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.AddBlockHashTransactions(exec, insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// AddBlockHashTransactionsGP adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
// Uses the global database handle and panics on error.
func (o *Block) AddBlockHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.AddBlockHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// AddBlockHashTransactions adds the given related objects to the existing relationships
// of the block, optionally inserting them as new records.
// Appends related to o.R.BlockHashTransactions.
// Sets related.R.BlockHash appropriately.
func (o *Block) AddBlockHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	var err error
	for _, rel := range related {
		if insert {
			queries.Assign(&rel.BlockHashID, o.Hash)
			if err = rel.Insert(exec, boil.Infer()); err != nil {
				return errors.Wrap(err, "failed to insert into foreign table")
			}
		} else {
			updateQuery := fmt.Sprintf(
				"UPDATE `transaction` SET %s WHERE %s",
				strmangle.SetParamNames("`", "`", 0, []string{"block_hash_id"}),
				strmangle.WhereClause("`", "`", 0, transactionPrimaryKeyColumns),
			)
			values := []interface{}{o.Hash, rel.ID}

			if boil.DebugMode {
				fmt.Fprintln(boil.DebugWriter, updateQuery)
				fmt.Fprintln(boil.DebugWriter, values)
			}
			if _, err = exec.Exec(updateQuery, values...); err != nil {
				return errors.Wrap(err, "failed to update foreign table")
			}

			queries.Assign(&rel.BlockHashID, o.Hash)
		}
	}

	if o.R == nil {
		o.R = &blockR{
			BlockHashTransactions: related,
		}
	} else {
		o.R.BlockHashTransactions = append(o.R.BlockHashTransactions, related...)
	}

	for _, rel := range related {
		if rel.R == nil {
			rel.R = &transactionR{
				BlockHash: o,
			}
		} else {
			rel.R.BlockHash = o
		}
	}
	return nil
}

// SetBlockHashTransactionsG removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Uses the global database handle.
func (o *Block) SetBlockHashTransactionsG(insert bool, related ...*Transaction) error {
	return o.SetBlockHashTransactions(boil.GetDB(), insert, related...)
}

// SetBlockHashTransactionsP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Panics on error.
func (o *Block) SetBlockHashTransactionsP(exec boil.Executor, insert bool, related ...*Transaction) {
	if err := o.SetBlockHashTransactions(exec, insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// SetBlockHashTransactionsGP removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
// Uses the global database handle and panics on error.
func (o *Block) SetBlockHashTransactionsGP(insert bool, related ...*Transaction) {
	if err := o.SetBlockHashTransactions(boil.GetDB(), insert, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// SetBlockHashTransactions removes all previously related items of the
// block replacing them completely with the passed
// in related items, optionally inserting them as new records.
// Sets o.R.BlockHash's BlockHashTransactions accordingly.
// Replaces o.R.BlockHashTransactions with related.
// Sets related.R.BlockHash's BlockHashTransactions accordingly.
func (o *Block) SetBlockHashTransactions(exec boil.Executor, insert bool, related ...*Transaction) error {
	query := "update `transaction` set `block_hash_id` = null where `block_hash_id` = ?"
	values := []interface{}{o.Hash}
	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, query)
		fmt.Fprintln(boil.DebugWriter, values)
	}
	_, err := exec.Exec(query, values...)
	if err != nil {
		return errors.Wrap(err, "failed to remove relationships before set")
	}

	if o.R != nil {
		for _, rel := range o.R.BlockHashTransactions {
			queries.SetScanner(&rel.BlockHashID, nil)
			if rel.R == nil {
				continue
			}

			rel.R.BlockHash = nil
		}
		o.R.BlockHashTransactions = nil
	}

	return o.AddBlockHashTransactions(exec, insert, related...)
}

// RemoveBlockHashTransactionsG relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Uses the global database handle.
func (o *Block) RemoveBlockHashTransactionsG(related ...*Transaction) error {
	return o.RemoveBlockHashTransactions(boil.GetDB(), related...)
}

// RemoveBlockHashTransactionsP relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Panics on error.
func (o *Block) RemoveBlockHashTransactionsP(exec boil.Executor, related ...*Transaction) {
	if err := o.RemoveBlockHashTransactions(exec, related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// RemoveBlockHashTransactionsGP relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
// Uses the global database handle and panics on error.
func (o *Block) RemoveBlockHashTransactionsGP(related ...*Transaction) {
	if err := o.RemoveBlockHashTransactions(boil.GetDB(), related...); err != nil {
		panic(boil.WrapErr(err))
	}
}

// RemoveBlockHashTransactions relationships from objects passed in.
// Removes related items from R.BlockHashTransactions (uses pointer comparison, removal does not keep order)
// Sets related.R.BlockHash.
func (o *Block) RemoveBlockHashTransactions(exec boil.Executor, related ...*Transaction) error {
	if len(related) == 0 {
		return nil
	}

	var err error
	for _, rel := range related {
		queries.SetScanner(&rel.BlockHashID, nil)
		if rel.R != nil {
			rel.R.BlockHash = nil
		}
		if err = rel.Update(exec, boil.Whitelist("block_hash_id")); err != nil {
			return err
		}
	}
	if o.R == nil {
		return nil
	}

	for _, rel := range related {
		for i, ri := range o.R.BlockHashTransactions {
			if rel != ri {
				continue
			}

			ln := len(o.R.BlockHashTransactions)
			if ln > 1 && i < ln-1 {
				o.R.BlockHashTransactions[i] = o.R.BlockHashTransactions[ln-1]
			}
			o.R.BlockHashTransactions = o.R.BlockHashTransactions[:ln-1]
			break
		}
	}

	return nil
}

// Blocks retrieves all the records using an executor.
func Blocks(mods ...qm.QueryMod) blockQuery {
	mods = append(mods, qm.From("`block`"))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"`block`.*"})
	}

	return blockQuery{q}
}

// FindBlockG retrieves a single record by ID.
func FindBlockG(iD uint64, selectCols ...string) (*Block, error) {
	return FindBlock(boil.GetDB(), iD, selectCols...)
}

// FindBlockP retrieves a single record by ID with an executor, and panics on error.
func FindBlockP(exec boil.Executor, iD uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(exec, iD, selectCols...)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return retobj
}

// FindBlockGP retrieves a single record by ID, and panics on error.
func FindBlockGP(iD uint64, selectCols ...string) *Block {
	retobj, err := FindBlock(boil.GetDB(), iD, selectCols...)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return retobj
}

// FindBlock retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindBlock(exec boil.Executor, iD uint64, selectCols ...string) (*Block, error) {
	blockObj := &Block{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from `block` where `id`=?", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(nil, exec, blockObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: unable to select from block")
	}

	return blockObj, nil
}

// InsertG a single record. See Insert for whitelist behavior description.
func (o *Block) InsertG(columns boil.Columns) error {
	return o.Insert(boil.GetDB(), columns)
}

// InsertP a single record using an executor, and panics on error. See Insert
// for whitelist behavior description.
func (o *Block) InsertP(exec boil.Executor, columns boil.Columns) {
	if err := o.Insert(exec, columns); err != nil {
		panic(boil.WrapErr(err))
	}
}

// InsertGP a single record, and panics on error. See Insert for whitelist
// behavior description.
func (o *Block) InsertGP(columns boil.Columns) {
	if err := o.Insert(boil.GetDB(), columns); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *Block) Insert(exec boil.Executor, columns boil.Columns) error {
	if o == nil {
		return errors.New("model: no block provided for insertion")
	}

	var err error

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	blockInsertCacheMut.RLock()
	cache, cached := blockInsertCache[key]
	blockInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			blockAllColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(blockType, blockMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO `block` (`%s`) %%sVALUES (%s)%%s", strings.Join(wl, "`,`"), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO `block` () VALUES ()%s%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			cache.retQuery = fmt.Sprintf("SELECT `%s` FROM `block` WHERE %s", strings.Join(returnColumns, "`,`"), strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}
	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "model: unable to insert into block")
	}

	var lastID int64
	var identifierCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["id"] {
		goto CacheNoHooks
	}

	identifierCols = []interface{}{
		o.ID,
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, identifierCols...)
	}
	err = exec.QueryRow(cache.retQuery, identifierCols...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	if err != nil {
		return errors.Wrap(err, "model: unable to populate default values for block")
	}

CacheNoHooks:
	if !cached {
		blockInsertCacheMut.Lock()
		blockInsertCache[key] = cache
		blockInsertCacheMut.Unlock()
	}

	return nil
}

// UpdateG a single Block record using the global executor.
// See Update for more documentation.
func (o *Block) UpdateG(columns boil.Columns) error {
	return o.Update(boil.GetDB(), columns)
}

// UpdateP uses an executor to update the Block, and panics on error.
// See Update for more documentation.
func (o *Block) UpdateP(exec boil.Executor, columns boil.Columns) {
	err := o.Update(exec, columns)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateGP a single Block record using the global executor. Panics on error.
// See Update for more documentation.
func (o *Block) UpdateGP(columns boil.Columns) {
	err := o.Update(boil.GetDB(), columns)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// Update uses an executor to update the Block.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *Block) Update(exec boil.Executor, columns boil.Columns) error {
	var err error
	key := makeCacheKey(columns, nil)
	blockUpdateCacheMut.RLock()
	cache, cached := blockUpdateCache[key]
	blockUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			blockAllColumns,
			blockPrimaryKeyColumns,
		)
		if len(wl) == 0 {
			return errors.New("model: unable to update block, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE `block` SET %s WHERE %s",
			strmangle.SetParamNames("`", "`", 0, wl),
			strmangle.WhereClause("`", "`", 0, blockPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, append(wl, blockPrimaryKeyColumns...))
		if err != nil {
			return err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, values)
	}
	_, err = exec.Exec(cache.query, values...)
	if err != nil {
		return errors.Wrap(err, "model: unable to update block row")
	}

	if !cached {
		blockUpdateCacheMut.Lock()
		blockUpdateCache[key] = cache
		blockUpdateCacheMut.Unlock()
	}

	return nil
}

// UpdateAllP updates all rows with matching column names, and panics on error.
func (q blockQuery) UpdateAllP(exec boil.Executor, cols M) {
	err := q.UpdateAll(exec, cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAllG updates all rows with the specified column values.
func (q blockQuery) UpdateAllG(cols M) error {
	return q.UpdateAll(boil.GetDB(), cols)
}

// UpdateAllGP updates all rows with the specified column values, and panics on error.
func (q blockQuery) UpdateAllGP(cols M) {
	err := q.UpdateAll(boil.GetDB(), cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAll updates all rows with the specified column values.
func (q blockQuery) UpdateAll(exec boil.Executor, cols M) error {
	queries.SetUpdate(q.Query, cols)

	_, err := q.Query.Exec(exec)
	if err != nil {
		return errors.Wrap(err, "model: unable to update all for block")
	}

	return nil
}

// UpdateAllG updates all rows with the specified column values.
func (o BlockSlice) UpdateAllG(cols M) error {
	return o.UpdateAll(boil.GetDB(), cols)
}

// UpdateAllGP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllGP(cols M) {
	err := o.UpdateAll(boil.GetDB(), cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAllP updates all rows with the specified column values, and panics on error.
func (o BlockSlice) UpdateAllP(exec boil.Executor, cols M) {
	err := o.UpdateAll(exec, cols)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o BlockSlice) UpdateAll(exec boil.Executor, cols M) error {
	ln := int64(len(o))
	if ln == 0 {
		return nil
	}

	if len(cols) == 0 {
		return errors.New("model: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE `block` SET %s WHERE %s",
		strmangle.SetParamNames("`", "`", 0, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o)))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}
	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to update all in block slice")
	}

	return nil
}

// UpsertG attempts an insert, and does an update or ignore on conflict.
func (o *Block) UpsertG(updateColumns, insertColumns boil.Columns) error {
	return o.Upsert(boil.GetDB(), updateColumns, insertColumns)
}

// UpsertGP attempts an insert, and does an update or ignore on conflict. Panics on error.
func (o *Block) UpsertGP(updateColumns, insertColumns boil.Columns) {
	if err := o.Upsert(boil.GetDB(), updateColumns, insertColumns); err != nil {
		panic(boil.WrapErr(err))
	}
}

// UpsertP attempts an insert using an executor, and does an update or ignore on conflict.
// UpsertP panics on error.
func (o *Block) UpsertP(exec boil.Executor, updateColumns, insertColumns boil.Columns) {
	if err := o.Upsert(exec, updateColumns, insertColumns); err != nil {
		panic(boil.WrapErr(err))
	}
}

var mySQLBlockUniqueColumns = []string{
	"id",
	"hash",
}

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *Block) Upsert(exec boil.Executor, updateColumns, insertColumns boil.Columns) error {
	if o == nil {
		return errors.New("model: no block provided for upsert")
	}

	nzDefaults := queries.NonZeroDefaultSet(blockColumnsWithDefault, o)
	nzUniques := queries.NonZeroDefaultSet(mySQLBlockUniqueColumns, o)

	if len(nzUniques) == 0 {
		return errors.New("cannot upsert with a table that cannot conflict on a unique column")
	}

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzUniques {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	blockUpsertCacheMut.RLock()
	cache, cached := blockUpsertCache[key]
	blockUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, ret := insertColumns.InsertColumnSet(
			blockAllColumns,
			blockColumnsWithDefault,
			blockColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			blockAllColumns,
			blockPrimaryKeyColumns,
		)

		if !updateColumns.IsNone() && len(update) == 0 {
			return errors.New("model: unable to upsert block, could not build update column list")
		}

		ret = strmangle.SetComplement(ret, nzUniques)
		cache.query = buildUpsertQueryMySQL(dialect, "`block`", update, insert)
		cache.retQuery = fmt.Sprintf(
			"SELECT %s FROM `block` WHERE %s",
			strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, ret), ","),
			strmangle.WhereClause("`", "`", 0, nzUniques),
		)

		cache.valueMapping, err = queries.BindMapping(blockType, blockMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(blockType, blockMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.query)
		fmt.Fprintln(boil.DebugWriter, vals)
	}
	result, err := exec.Exec(cache.query, vals...)

	if err != nil {
		return errors.Wrap(err, "model: unable to upsert for block")
	}

	var lastID int64
	var uniqueMap []uint64
	var nzUniqueCols []interface{}

	if len(cache.retMapping) == 0 {
		goto CacheNoHooks
	}

	lastID, err = result.LastInsertId()
	if err != nil {
		return ErrSyncFail
	}

	o.ID = uint64(lastID)
	if lastID != 0 && len(cache.retMapping) == 1 && cache.retMapping[0] == blockMapping["id"] {
		goto CacheNoHooks
	}

	uniqueMap, err = queries.BindMapping(blockType, blockMapping, nzUniques)
	if err != nil {
		return errors.Wrap(err, "model: unable to retrieve unique values for block")
	}
	nzUniqueCols = queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), uniqueMap)

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, cache.retQuery)
		fmt.Fprintln(boil.DebugWriter, nzUniqueCols...)
	}
	err = exec.QueryRow(cache.retQuery, nzUniqueCols...).Scan(returns...)
	if err != nil {
		return errors.Wrap(err, "model: unable to populate default values for block")
	}

CacheNoHooks:
	if !cached {
		blockUpsertCacheMut.Lock()
		blockUpsertCache[key] = cache
		blockUpsertCacheMut.Unlock()
	}

	return nil
}

// DeleteG deletes a single Block record.
// DeleteG will match against the primary key column to find the record to delete.
func (o *Block) DeleteG() error {
	return o.Delete(boil.GetDB())
}

// DeleteP deletes a single Block record with an executor.
// DeleteP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteP(exec boil.Executor) {
	err := o.Delete(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteGP deletes a single Block record.
// DeleteGP will match against the primary key column to find the record to delete.
// Panics on error.
func (o *Block) DeleteGP() {
	err := o.Delete(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// Delete deletes a single Block record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *Block) Delete(exec boil.Executor) error {
	if o == nil {
		return errors.New("model: no Block provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), blockPrimaryKeyMapping)
	sql := "DELETE FROM `block` WHERE `id`=?"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args...)
	}
	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete from block")
	}

	return nil
}

func (q blockQuery) DeleteAllG() error {
	return q.DeleteAll(boil.GetDB())
}

// DeleteAllP deletes all rows, and panics on error.
func (q blockQuery) DeleteAllP(exec boil.Executor) {
	err := q.DeleteAll(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAllGP deletes all rows, and panics on error.
func (q blockQuery) DeleteAllGP() {
	err := q.DeleteAll(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAll deletes all matching rows.
func (q blockQuery) DeleteAll(exec boil.Executor) error {
	if q.Query == nil {
		return errors.New("model: no blockQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	_, err := q.Query.Exec(exec)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete all from block")
	}

	return nil
}

// DeleteAllG deletes all rows in the slice.
func (o BlockSlice) DeleteAllG() error {
	return o.DeleteAll(boil.GetDB())
}

// DeleteAllP deletes all rows in the slice, using an executor, and panics on error.
func (o BlockSlice) DeleteAllP(exec boil.Executor) {
	err := o.DeleteAll(exec)
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAllGP deletes all rows in the slice, and panics on error.
func (o BlockSlice) DeleteAllGP() {
	err := o.DeleteAll(boil.GetDB())
	if err != nil {
		panic(boil.WrapErr(err))
	}
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o BlockSlice) DeleteAll(exec boil.Executor) error {
	if len(o) == 0 {
		return nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM `block` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(o))

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, args)
	}
	_, err := exec.Exec(sql, args...)
	if err != nil {
		return errors.Wrap(err, "model: unable to delete all from block slice")
	}

	return nil
}

// ReloadG refetches the object from the database using the primary keys.
func (o *Block) ReloadG() error {
	if o == nil {
		return errors.New("model: no Block provided for reload")
	}

	return o.Reload(boil.GetDB())
}

// ReloadP refetches the object from the database with an executor. Panics on error.
func (o *Block) ReloadP(exec boil.Executor) {
	if err := o.Reload(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadGP refetches the object from the database and panics on error.
func (o *Block) ReloadGP() {
	if err := o.Reload(boil.GetDB()); err != nil {
		panic(boil.WrapErr(err))
	}
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *Block) Reload(exec boil.Executor) error {
	ret, err := FindBlock(exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAllG refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAllG() error {
	if o == nil {
		return errors.New("model: empty BlockSlice provided for reload all")
	}

	return o.ReloadAll(boil.GetDB())
}

// ReloadAllP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllP(exec boil.Executor) {
	if err := o.ReloadAll(exec); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadAllGP refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
// Panics on error.
func (o *BlockSlice) ReloadAllGP() {
	if err := o.ReloadAll(boil.GetDB()); err != nil {
		panic(boil.WrapErr(err))
	}
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *BlockSlice) ReloadAll(exec boil.Executor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := BlockSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), blockPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT `block`.* FROM `block` WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 0, blockPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(nil, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "model: unable to reload all in BlockSlice")
	}

	*o = slice

	return nil
}

// BlockExistsG checks if the Block row exists.
func BlockExistsG(iD uint64) (bool, error) {
	return BlockExists(boil.GetDB(), iD)
}

// BlockExistsP checks if the Block row exists. Panics on error.
func BlockExistsP(exec boil.Executor, iD uint64) bool {
	e, err := BlockExists(exec, iD)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// BlockExistsGP checks if the Block row exists. Panics on error.
func BlockExistsGP(iD uint64) bool {
	e, err := BlockExists(boil.GetDB(), iD)
	if err != nil {
		panic(boil.WrapErr(err))
	}

	return e
}

// BlockExists checks if the Block row exists.
func BlockExists(exec boil.Executor, iD uint64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from `block` where `id`=? limit 1)"

	if boil.DebugMode {
		fmt.Fprintln(boil.DebugWriter, sql)
		fmt.Fprintln(boil.DebugWriter, iD)
	}
	row := exec.QueryRow(sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "model: unable to check if block exists")
	}

	return exists, nil
}
